{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../components/classification/ind_to_name.json', 'r') as f:\n",
    "    ind_to_name = json.load(f)\n",
    "with open('../../components/classification/categories.json', 'r') as f:\n",
    "    categories = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('../../datasets/classification/numpy/X.npy')\n",
    "y = np.load('../../datasets/classification/numpy/y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "values, counts = np.unique(y, return_counts=True)\n",
    "mapping = { values[i]:counts[i] for i in range(len(values))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, train_indices, test_indices = train_test_split(X, y, np.arange(len(y)), test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask = np.zeros(len(y), dtype=bool)\n",
    "test_mask = np.zeros(len(y), dtype=bool)\n",
    "\n",
    "train_mask[train_indices] = True\n",
    "test_mask[test_indices] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6340956340956341"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0. , 0. , 0.8, 0. , 0. , 0.2],\n",
       "       [0.8, 0. , 0.2, 0. , 0. , 0. ],\n",
       "       [0. , 0.8, 0. , 0. , 0. , 0.2],\n",
       "       ...,\n",
       "       [0. , 0. , 0. , 0.2, 0.6, 0.2],\n",
       "       [0. , 0. , 1. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0.8, 0. , 0. , 0.2]])"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gcn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.utils import to_dense_adj\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.load('../../datasets/classification/pt/data.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.y = torch.from_numpy(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.num_features = data.x.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.train_mask = train_mask\n",
    "data.test_mask = test_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.num_classes = len(torch.unique(data.y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 20882], num_nodes=1922, x=[1922, 15], y=[1922], num_features=15, train_mask=[1922], test_mask=[1922], num_classes=6)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.x = data.x.to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, num_features, hidden_features, num_classes):\n",
    "        super().__init__() ## initialize the base class (i.e. torch nn module)\n",
    "        self.conv1 = GCNConv(num_features, hidden_features) # convolutional layer - performs message passing, embeddings from 15 features to 8\n",
    "        self.conv2 = GCNConv(hidden_features, num_classes)  # convolutional layer - performs message passing, embeddings from 8 features to 6\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index # get the feature mat and adjacency mat\n",
    "        h = self.conv1(x, edge_index)           # compute the first convolutional layer; 15 -> 8\n",
    "        h = F.relu(h)                           # applies max(0, x) for each element in the matrix, essentially replaces all negative values by 0\n",
    "        h = self.conv2(h, edge_index)           # transforms from 8 -> 6\n",
    "        z = h.argmax(dim=1)                     # find the index w/ highest classifcation\n",
    "        \n",
    "        return h, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001) # update the model parameters\n",
    "    model.train()                                              # set it to training mode\n",
    "    logits, _ = model(data)                                    # compute the final embeddings\n",
    "    \n",
    "    loss = F.cross_entropy(logits[data.train_mask], data.y[data.train_mask]) # compute the loss on the training mask\n",
    "    optimizer.zero_grad()                                      # clear gradient\n",
    "    loss.backward()                                            # back propagation\n",
    "    optimizer.step()                                           # updates the model's parameters\n",
    "    \n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_degree(data, i):\n",
    "    row_sums = torch.sum(to_dense_adj(data.edge_index), dim=1)\n",
    "    return row_sums.flatten()[i].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, data, verbose=False):\n",
    "    model.eval()\n",
    "    _, pred = model(data)\n",
    "\n",
    "    if verbose:\n",
    "        incorrect_indices = (pred != data.y).nonzero(as_tuple=True)[0]\n",
    "        test_mask_indices = incorrect_indices[data.test_mask[incorrect_indices]]\n",
    "        print(\"Incorrect Predictions Indices:\", test_mask_indices.tolist())\n",
    "        for i in test_mask_indices:\n",
    "            print(f\"Name: {ind_to_name[str(i.item())]}\\n\\tPredicted: {categories[str(pred[i].item())]}\\n\\tTrue: {categories[str(data.y[i].item())]}\\n\\tDegree: {get_degree(data, i.item())}\")\n",
    "    \n",
    "    acc = (pred[data.test_mask] == data.y[data.test_mask]).sum().item() / data.test_mask.sum().item()\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GCN(data.num_features, 8, data.num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 1.9438, Accuracy: 0.1663\n",
      "Epoch: 100, Loss: 1.7114, Accuracy: 0.2557\n",
      "Epoch: 200, Loss: 1.6459, Accuracy: 0.4595\n",
      "Epoch: 300, Loss: 1.5585, Accuracy: 0.5613\n",
      "Epoch: 400, Loss: 1.4593, Accuracy: 0.5967\n",
      "Epoch: 500, Loss: 1.3551, Accuracy: 0.6383\n",
      "Epoch: 600, Loss: 1.2517, Accuracy: 0.6590\n",
      "Epoch: 700, Loss: 1.1531, Accuracy: 0.6881\n",
      "Epoch: 800, Loss: 1.0608, Accuracy: 0.7152\n",
      "Epoch: 900, Loss: 0.9772, Accuracy: 0.7339\n",
      "Epoch: 1000, Loss: 0.9027, Accuracy: 0.7505\n",
      "Epoch: 1100, Loss: 0.8371, Accuracy: 0.7672\n",
      "Epoch: 1200, Loss: 0.7790, Accuracy: 0.7796\n",
      "Epoch: 1300, Loss: 0.7270, Accuracy: 0.7817\n",
      "Epoch: 1400, Loss: 0.6811, Accuracy: 0.7963\n",
      "Epoch: 1500, Loss: 0.6402, Accuracy: 0.8025\n",
      "Epoch: 1600, Loss: 0.6034, Accuracy: 0.8170\n",
      "Epoch: 1700, Loss: 0.5712, Accuracy: 0.8274\n",
      "Epoch: 1800, Loss: 0.5439, Accuracy: 0.8358\n",
      "Epoch: 1900, Loss: 0.5201, Accuracy: 0.8358\n",
      "Epoch: 2000, Loss: 0.4997, Accuracy: 0.8420\n",
      "Epoch: 2100, Loss: 0.4827, Accuracy: 0.8441\n",
      "Epoch: 2200, Loss: 0.4679, Accuracy: 0.8482\n",
      "Epoch: 2300, Loss: 0.4544, Accuracy: 0.8565\n",
      "Epoch: 2400, Loss: 0.4425, Accuracy: 0.8586\n",
      "Epoch: 2500, Loss: 0.4319, Accuracy: 0.8607\n",
      "Epoch: 2600, Loss: 0.4225, Accuracy: 0.8711\n",
      "Epoch: 2700, Loss: 0.4143, Accuracy: 0.8690\n",
      "Epoch: 2800, Loss: 0.4069, Accuracy: 0.8711\n",
      "Epoch: 2900, Loss: 0.3998, Accuracy: 0.8773\n",
      "Epoch: 3000, Loss: 0.3933, Accuracy: 0.8794\n",
      "Epoch: 3100, Loss: 0.3878, Accuracy: 0.8773\n",
      "Epoch: 3200, Loss: 0.3830, Accuracy: 0.8753\n",
      "Epoch: 3300, Loss: 0.3785, Accuracy: 0.8753\n",
      "Epoch: 3400, Loss: 0.3745, Accuracy: 0.8773\n",
      "Epoch: 3500, Loss: 0.3707, Accuracy: 0.8815\n",
      "Epoch: 3600, Loss: 0.3673, Accuracy: 0.8815\n",
      "Epoch: 3700, Loss: 0.3642, Accuracy: 0.8794\n",
      "Epoch: 3800, Loss: 0.3614, Accuracy: 0.8815\n",
      "Epoch: 3900, Loss: 0.3589, Accuracy: 0.8815\n",
      "Epoch: 4000, Loss: 0.3568, Accuracy: 0.8815\n",
      "Epoch: 4100, Loss: 0.3548, Accuracy: 0.8815\n",
      "Epoch: 4200, Loss: 0.3530, Accuracy: 0.8836\n",
      "Epoch: 4300, Loss: 0.3512, Accuracy: 0.8857\n",
      "Epoch: 4400, Loss: 0.3494, Accuracy: 0.8877\n",
      "Epoch: 4500, Loss: 0.3477, Accuracy: 0.8877\n",
      "Epoch: 4600, Loss: 0.3460, Accuracy: 0.8857\n",
      "Epoch: 4700, Loss: 0.3444, Accuracy: 0.8857\n",
      "Epoch: 4800, Loss: 0.3428, Accuracy: 0.8857\n",
      "Epoch: 4900, Loss: 0.3413, Accuracy: 0.8857\n",
      "Epoch: 5000, Loss: 0.3399, Accuracy: 0.8857\n",
      "Epoch: 5100, Loss: 0.3385, Accuracy: 0.8857\n",
      "Epoch: 5200, Loss: 0.3370, Accuracy: 0.8857\n",
      "Epoch: 5300, Loss: 0.3356, Accuracy: 0.8857\n",
      "Epoch: 5400, Loss: 0.3343, Accuracy: 0.8857\n",
      "Epoch: 5500, Loss: 0.3330, Accuracy: 0.8857\n",
      "Epoch: 5600, Loss: 0.3317, Accuracy: 0.8877\n",
      "Epoch: 5700, Loss: 0.3305, Accuracy: 0.8898\n",
      "Epoch: 5800, Loss: 0.3292, Accuracy: 0.8898\n",
      "Epoch: 5900, Loss: 0.3280, Accuracy: 0.8898\n",
      "Epoch: 6000, Loss: 0.3272, Accuracy: 0.8919\n",
      "Epoch: 6100, Loss: 0.3264, Accuracy: 0.8919\n",
      "Epoch: 6200, Loss: 0.3256, Accuracy: 0.8919\n",
      "Epoch: 6300, Loss: 0.3248, Accuracy: 0.8919\n",
      "Epoch: 6400, Loss: 0.3240, Accuracy: 0.8877\n",
      "Epoch: 6500, Loss: 0.3233, Accuracy: 0.8877\n",
      "Epoch: 6600, Loss: 0.3226, Accuracy: 0.8877\n",
      "Epoch: 6700, Loss: 0.3218, Accuracy: 0.8898\n",
      "Epoch: 6800, Loss: 0.3212, Accuracy: 0.8898\n",
      "Epoch: 6900, Loss: 0.3206, Accuracy: 0.8857\n",
      "Epoch: 7000, Loss: 0.3200, Accuracy: 0.8877\n",
      "Epoch: 7100, Loss: 0.3195, Accuracy: 0.8877\n",
      "Epoch: 7200, Loss: 0.3190, Accuracy: 0.8877\n",
      "Epoch: 7300, Loss: 0.3185, Accuracy: 0.8877\n",
      "Epoch: 7400, Loss: 0.3179, Accuracy: 0.8877\n",
      "Epoch: 7500, Loss: 0.3174, Accuracy: 0.8898\n",
      "Epoch: 7600, Loss: 0.3169, Accuracy: 0.8898\n",
      "Epoch: 7700, Loss: 0.3164, Accuracy: 0.8898\n",
      "Epoch: 7800, Loss: 0.3159, Accuracy: 0.8877\n",
      "Epoch: 7900, Loss: 0.3154, Accuracy: 0.8877\n",
      "Epoch: 8000, Loss: 0.3150, Accuracy: 0.8877\n",
      "Epoch: 8100, Loss: 0.3145, Accuracy: 0.8877\n",
      "Epoch: 8200, Loss: 0.3141, Accuracy: 0.8877\n",
      "Epoch: 8300, Loss: 0.3136, Accuracy: 0.8877\n",
      "Epoch: 8400, Loss: 0.3132, Accuracy: 0.8898\n",
      "Epoch: 8500, Loss: 0.3128, Accuracy: 0.8919\n",
      "Epoch: 8600, Loss: 0.3123, Accuracy: 0.8919\n",
      "Epoch: 8700, Loss: 0.3120, Accuracy: 0.8919\n",
      "Epoch: 8800, Loss: 0.3117, Accuracy: 0.8919\n",
      "Epoch: 8900, Loss: 0.3113, Accuracy: 0.8919\n",
      "Epoch: 9000, Loss: 0.3109, Accuracy: 0.8919\n",
      "Epoch: 9100, Loss: 0.3104, Accuracy: 0.8919\n",
      "Epoch: 9200, Loss: 0.3100, Accuracy: 0.8919\n",
      "Epoch: 9300, Loss: 0.3097, Accuracy: 0.8919\n",
      "Epoch: 9400, Loss: 0.3094, Accuracy: 0.8940\n",
      "Epoch: 9500, Loss: 0.3092, Accuracy: 0.8940\n",
      "Epoch: 9600, Loss: 0.3090, Accuracy: 0.8940\n",
      "Epoch: 9700, Loss: 0.3088, Accuracy: 0.8940\n",
      "Epoch: 9800, Loss: 0.3086, Accuracy: 0.8919\n",
      "Epoch: 9900, Loss: 0.3082, Accuracy: 0.8940\n"
     ]
    }
   ],
   "source": [
    "del model\n",
    "model = GCN(data.num_features, 8, data.num_classes)\n",
    "for epoch in range(0, 10000):\n",
    "    loss = train(model, data)\n",
    "    if epoch % 100 == 0:\n",
    "        acc = test(model, data)\n",
    "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Accuracy: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect Predictions Indices: [184, 192, 210, 212, 231, 237, 250, 251, 254, 331, 366, 398, 415, 494, 495, 514, 518, 529, 538, 544, 585, 602, 607, 610, 677, 700, 741, 855, 886, 965, 1052, 1133, 1196, 1208, 1259, 1283, 1293, 1356, 1417, 1440, 1456, 1458, 1501, 1511, 1540, 1559, 1618, 1619, 1625, 1658, 1664, 1730, 1796, 1862]\n",
      "Name: Teyana Taylor\n",
      "\tPredicted: hip hop\n",
      "\tTrue: pop\n",
      "\tDegree: 18.0\n",
      "Name: Allie X\n",
      "\tPredicted: uk pop\n",
      "\tTrue: pop\n",
      "\tDegree: 5.0\n",
      "Name: Whitney Houston\n",
      "\tPredicted: hip hop\n",
      "\tTrue: pop\n",
      "\tDegree: 7.0\n",
      "Name: DJ Jazzy Jeff & The Fresh Prince\n",
      "\tPredicted: filmi\n",
      "\tTrue: hip hop\n",
      "\tDegree: 1.0\n",
      "Name: Matt Simons\n",
      "\tPredicted: pop\n",
      "\tTrue: uk pop\n",
      "\tDegree: 1.0\n",
      "Name: Zak Abel\n",
      "\tPredicted: pop\n",
      "\tTrue: uk pop\n",
      "\tDegree: 8.0\n",
      "Name: Robinson\n",
      "\tPredicted: electro house\n",
      "\tTrue: uk pop\n",
      "\tDegree: 4.0\n",
      "Name: Tobtok\n",
      "\tPredicted: uk pop\n",
      "\tTrue: electro house\n",
      "\tDegree: 18.0\n",
      "Name: M-22\n",
      "\tPredicted: pop\n",
      "\tTrue: uk pop\n",
      "\tDegree: 17.0\n",
      "Name: Rich The Kid\n",
      "\tPredicted: pop\n",
      "\tTrue: hip hop\n",
      "\tDegree: 44.0\n",
      "Name: ILLENIUM\n",
      "\tPredicted: electro house\n",
      "\tTrue: pop\n",
      "\tDegree: 53.0\n",
      "Name: Frank Walker\n",
      "\tPredicted: pop\n",
      "\tTrue: electro house\n",
      "\tDegree: 19.0\n",
      "Name: Rizzle Kicks\n",
      "\tPredicted: hip hop\n",
      "\tTrue: uk pop\n",
      "\tDegree: 4.0\n",
      "Name: Gryffin\n",
      "\tPredicted: electro house\n",
      "\tTrue: pop\n",
      "\tDegree: 37.0\n",
      "Name: LVNDSCAPE\n",
      "\tPredicted: uk pop\n",
      "\tTrue: electro house\n",
      "\tDegree: 3.0\n",
      "Name: Bhad Bhabie\n",
      "\tPredicted: hip hop\n",
      "\tTrue: pop\n",
      "\tDegree: 11.0\n",
      "Name: James Blake\n",
      "\tPredicted: pop\n",
      "\tTrue: uk pop\n",
      "\tDegree: 12.0\n",
      "Name: Wretch 32\n",
      "\tPredicted: pop\n",
      "\tTrue: uk pop\n",
      "\tDegree: 11.0\n",
      "Name: Gwen Stefani\n",
      "\tPredicted: hip hop\n",
      "\tTrue: pop\n",
      "\tDegree: 6.0\n",
      "Name: Sofia Carson\n",
      "\tPredicted: electro house\n",
      "\tTrue: pop\n",
      "\tDegree: 4.0\n",
      "Name: MNEK\n",
      "\tPredicted: electro house\n",
      "\tTrue: uk pop\n",
      "\tDegree: 17.0\n",
      "Name: PRETTYMUCH\n",
      "\tPredicted: hip hop\n",
      "\tTrue: pop\n",
      "\tDegree: 3.0\n",
      "Name: Katy B\n",
      "\tPredicted: electro house\n",
      "\tTrue: uk pop\n",
      "\tDegree: 5.0\n",
      "Name: Alicia Keys\n",
      "\tPredicted: hip hop\n",
      "\tTrue: pop\n",
      "\tDegree: 29.0\n",
      "Name: Call Me Loop\n",
      "\tPredicted: german hip hop\n",
      "\tTrue: uk pop\n",
      "\tDegree: 4.0\n",
      "Name: Ant Saunders\n",
      "\tPredicted: uk pop\n",
      "\tTrue: pop\n",
      "\tDegree: 1.0\n",
      "Name: Alan Walker\n",
      "\tPredicted: pop\n",
      "\tTrue: electro house\n",
      "\tDegree: 36.0\n",
      "Name: Dove Cameron\n",
      "\tPredicted: electro house\n",
      "\tTrue: pop\n",
      "\tDegree: 3.0\n",
      "Name: Sean Kingston\n",
      "\tPredicted: hip hop\n",
      "\tTrue: pop\n",
      "\tDegree: 22.0\n",
      "Name: Ross Lynch\n",
      "\tPredicted: uk pop\n",
      "\tTrue: pop\n",
      "\tDegree: 1.0\n",
      "Name: China Anne McClain\n",
      "\tPredicted: electro house\n",
      "\tTrue: pop\n",
      "\tDegree: 1.0\n",
      "Name: Grant\n",
      "\tPredicted: uk pop\n",
      "\tTrue: electro house\n",
      "\tDegree: 2.0\n",
      "Name: St. Lundi\n",
      "\tPredicted: pop\n",
      "\tTrue: uk pop\n",
      "\tDegree: 2.0\n",
      "Name: Christina Milian\n",
      "\tPredicted: pop\n",
      "\tTrue: hip hop\n",
      "\tDegree: 4.0\n",
      "Name: Kailee Morgue\n",
      "\tPredicted: uk pop\n",
      "\tTrue: pop\n",
      "\tDegree: 1.0\n",
      "Name: Queen Latifah\n",
      "\tPredicted: pop\n",
      "\tTrue: hip hop\n",
      "\tDegree: 2.0\n",
      "Name: Pixie Lott\n",
      "\tPredicted: pop\n",
      "\tTrue: uk pop\n",
      "\tDegree: 3.0\n",
      "Name: Kota the Friend\n",
      "\tPredicted: uk pop\n",
      "\tTrue: hip hop\n",
      "\tDegree: 2.0\n",
      "Name: APRE\n",
      "\tPredicted: pop\n",
      "\tTrue: uk pop\n",
      "\tDegree: 1.0\n",
      "Name: DUSK\n",
      "\tPredicted: german hip hop\n",
      "\tTrue: uk pop\n",
      "\tDegree: 2.0\n",
      "Name: Jay Pryor\n",
      "\tPredicted: pop\n",
      "\tTrue: electro house\n",
      "\tDegree: 4.0\n",
      "Name: Haywyre\n",
      "\tPredicted: uk pop\n",
      "\tTrue: electro house\n",
      "\tDegree: 2.0\n",
      "Name: Black Caviar\n",
      "\tPredicted: pop\n",
      "\tTrue: electro house\n",
      "\tDegree: 6.0\n",
      "Name: Baby Tate\n",
      "\tPredicted: hip hop\n",
      "\tTrue: pop\n",
      "\tDegree: 5.0\n",
      "Name: Olivia Lunny\n",
      "\tPredicted: german hip hop\n",
      "\tTrue: uk pop\n",
      "\tDegree: 1.0\n",
      "Name: Mae Muller\n",
      "\tPredicted: pop\n",
      "\tTrue: uk pop\n",
      "\tDegree: 4.0\n",
      "Name: Nao\n",
      "\tPredicted: uk pop\n",
      "\tTrue: pop\n",
      "\tDegree: 2.0\n",
      "Name: DJ Shadow\n",
      "\tPredicted: electro house\n",
      "\tTrue: hip hop\n",
      "\tDegree: 1.0\n",
      "Name: David Banner\n",
      "\tPredicted: pop\n",
      "\tTrue: hip hop\n",
      "\tDegree: 1.0\n",
      "Name: Said The Sky\n",
      "\tPredicted: electro house\n",
      "\tTrue: pop\n",
      "\tDegree: 7.0\n",
      "Name: Vato Gonzalez\n",
      "\tPredicted: hip hop\n",
      "\tTrue: electro house\n",
      "\tDegree: 1.0\n",
      "Name: 3OH!3\n",
      "\tPredicted: electro house\n",
      "\tTrue: pop\n",
      "\tDegree: 1.0\n",
      "Name: Jay Dee\n",
      "\tPredicted: german hip hop\n",
      "\tTrue: hip hop\n",
      "\tDegree: 1.0\n",
      "Name: Ivan Gough\n",
      "\tPredicted: uk pop\n",
      "\tTrue: electro house\n",
      "\tDegree: 5.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8877338877338877"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(model, data, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steve Aoki 131.0\n"
     ]
    }
   ],
   "source": [
    "row_sums = torch.sum(to_dense_adj(data.edge_index), dim=1)\n",
    "max_sum_index = torch.argmax(row_sums)\n",
    "print(ind_to_name[str(max_sum_index.item())], row_sums.flatten()[max_sum_index.item()].item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spotify",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
